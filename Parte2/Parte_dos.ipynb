{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importacion de bibliotecas\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llamamos los archivos csv y json\n",
    "licencias_pd = pd.read_csv('Licencias_Locales_202104.csv', delimiter=';')\n",
    "terrazas_pd = pd.read_csv('Terrazas_202104.csv', delimiter=';', encoding='ISO-8859-1')\n",
    "locales_pd = pd.read_csv('Locales_202104.csv', delimiter=';', encoding='ISO-8859-1')\n",
    "books_pd = pd.read_json('books_edit_corrected.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension archivo licencias.csv:  (132171, 46)\n",
      "dimension archivo terrazas.csv:  (6275, 57)\n",
      "dimension archivo locales.csv:  (148216, 40)\n",
      "dimension archivo books.json:  (431, 11)\n",
      "\n",
      "dimension archivo licencias.csv editado:  (132171, 43)\n",
      "dimension archivo terrazas.csv editado:  (6275, 53)\n",
      "dimension archivo locales.csv editado:  (148216, 28)\n",
      "dimension archivo books.json editado:  (431, 11)\n"
     ]
    }
   ],
   "source": [
    "# eliminar columnas con mas del 50% de datos nulos\n",
    "licencias_copy = licencias_pd.copy()\n",
    "terrazas_copy = terrazas_pd.copy()\n",
    "locales_copy = locales_pd.copy()\n",
    "books_copy = books_pd.copy()\n",
    "print(\"dimension archivo licencias.csv: \",licencias_copy.shape)\n",
    "print(\"dimension archivo terrazas.csv: \",terrazas_copy.shape)\n",
    "print(\"dimension archivo locales.csv: \",locales_copy.shape)\n",
    "print(\"dimension archivo books.json: \",books_copy.shape)\n",
    "datasets = [licencias_copy, terrazas_copy, locales_copy, books_copy]\n",
    "\n",
    "for dataset in datasets:\n",
    "    threshold = len(dataset) * 0.5\n",
    "    dataset.dropna(thresh=threshold, axis=1, inplace=True)\n",
    "\n",
    "print(\"\\ndimension archivo licencias.csv editado: \",licencias_copy.shape)\n",
    "print(\"dimension archivo terrazas.csv editado: \",terrazas_copy.shape)\n",
    "print(\"dimension archivo locales.csv editado: \",locales_copy.shape)\n",
    "print(\"dimension archivo books.json editado: \",books_copy.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6275 entries, 0 to 6274\n",
      "Data columns (total 53 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   id_terraza                      6275 non-null   int64  \n",
      " 1   id_local                        6275 non-null   int64  \n",
      " 2   id_distrito_local               6275 non-null   int64  \n",
      " 3   desc_distrito_local             6275 non-null   object \n",
      " 4   id_barrio_local                 6275 non-null   int64  \n",
      " 5   desc_barrio_local               6275 non-null   object \n",
      " 6   id_ndp_edificio                 6275 non-null   int64  \n",
      " 7   id_clase_ndp_edificio           6275 non-null   int64  \n",
      " 8   id_vial_edificio                6275 non-null   int64  \n",
      " 9   clase_vial_edificio             6275 non-null   object \n",
      " 10  desc_vial_edificio              6275 non-null   object \n",
      " 11  nom_edificio                    6275 non-null   object \n",
      " 12  num_edificio                    6275 non-null   int64  \n",
      " 13  Cod_Postal                      6275 non-null   int64  \n",
      " 14  coordenada_x_local              6275 non-null   object \n",
      " 15  coordenada_y_local              6275 non-null   object \n",
      " 16  id_tipo_acceso_local            6275 non-null   int64  \n",
      " 17  desc_tipo_acceso_local          6275 non-null   object \n",
      " 18  id_situacion_local              6275 non-null   int64  \n",
      " 19  desc_situacion_local            6275 non-null   object \n",
      " 20  secuencial_local_PC             6275 non-null   int64  \n",
      " 21  id_planta_agrupado              6267 non-null   object \n",
      " 22  rotulo                          6275 non-null   object \n",
      " 23  id_periodo_terraza              6275 non-null   int64  \n",
      " 24  desc_periodo_terraza            6275 non-null   object \n",
      " 25  id_situacion_terraza            6275 non-null   int64  \n",
      " 26  desc_situacion_terraza          6275 non-null   object \n",
      " 27  Superficie_ES                   6275 non-null   object \n",
      " 28  Superficie_RA                   4809 non-null   object \n",
      " 29  Fecha_confir_ult_decreto_resol  6275 non-null   object \n",
      " 30  id_ndp_terraza                  6275 non-null   int64  \n",
      " 31  id_clase_ndp_terraza            6275 non-null   int64  \n",
      " 32  ID_VIAL                         6275 non-null   int64  \n",
      " 33  DESC_CLASE                      6275 non-null   object \n",
      " 34  DESC_NOMBRE                     6275 non-null   object \n",
      " 35  nom_terraza                     6275 non-null   object \n",
      " 36  num_terraza                     6275 non-null   int64  \n",
      " 37  cal_terraza                     6275 non-null   object \n",
      " 38  desc_ubicacion_terraza          6275 non-null   object \n",
      " 39  hora_ini_LJ_es                  6275 non-null   object \n",
      " 40  hora_fin_LJ_es                  6275 non-null   object \n",
      " 41  hora_ini_LJ_ra                  4809 non-null   object \n",
      " 42  hora_fin_LJ_ra                  4809 non-null   object \n",
      " 43  hora_ini_VS_es                  6275 non-null   object \n",
      " 44  hora_fin_VS_es                  6275 non-null   object \n",
      " 45  hora_ini_VS_ra                  4809 non-null   object \n",
      " 46  hora_fin_VS_ra                  4809 non-null   object \n",
      " 47  mesas_aux_es                    6275 non-null   int64  \n",
      " 48  mesas_aux_ra                    4770 non-null   float64\n",
      " 49  mesas_es                        6275 non-null   int64  \n",
      " 50  mesas_ra                        4770 non-null   float64\n",
      " 51  sillas_es                       6275 non-null   int64  \n",
      " 52  sillas_ra                       6275 non-null   object \n",
      "dtypes: float64(2), int64(21), object(30)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "terrazas_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estandarizar columnas numericas con StandardScaler\n",
    "datasets = [licencias_copy, terrazas_copy, locales_copy, books_copy]\n",
    "\n",
    "#cambiar decimal de ',' a '.'\n",
    "terrazas_copy['Superficie_ES'] = terrazas_copy['Superficie_ES'].str.replace(',', '.')\n",
    "terrazas_copy['Superficie_RA'] = terrazas_copy['Superficie_RA'].str.replace(',', '.')\n",
    "# primero creamos en dataset Terrazas una columna Superficie_TO que es la suma de Superficie_ES y Superficie_RA\n",
    "terrazas_copy['Superficie_ES'] = terrazas_copy['Superficie_ES'].astype(float)\n",
    "terrazas_copy['Superficie_RA'] = terrazas_copy['Superficie_RA'].astype(float)\n",
    "terrazas_copy['Superficie_TO'] = terrazas_copy['Superficie_ES'] + terrazas_copy['Superficie_RA']\n",
    "\n",
    "\n",
    "for dataset in datasets:\n",
    "    numeric_cols = dataset.select_dtypes(include=['float64', 'int64']).columns\n",
    "     # Filtrar columnas que NO empiezan con \"id\"\n",
    "    numeric_cols_to_scale = [col for col in numeric_cols if not col.startswith('id')]\n",
    "    if numeric_cols_to_scale:\n",
    "        scaler = StandardScaler()\n",
    "        dataset[numeric_cols_to_scale] = scaler.fit_transform(dataset[numeric_cols_to_scale]).round(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creacion columna Ratio de Superficie_TO/id_terraza en terrazas.csv\n",
    "terrazas_copy['Ratio'] = terrazas_copy['Superficie_TO'] / terrazas_copy['id_terraza']\n",
    "# guardamos el archivo editado\n",
    "terrazas_copy.to_csv('Terrazas_Normalizadas.csv', index=False)\n",
    "\n",
    "# Producto de num_acceso * id_tipo_licencia en licencias.csv\n",
    "licencias_copy['Producto'] = licencias_copy['num_acceso'] * licencias_copy['id_tipo_licencia']\n",
    "\n",
    "# Residuo desc_seccion_censal_local /num_edificio en locales.csv\n",
    "locales_copy['Residuo'] = locales_copy['desc_seccion_censal_local'] % locales_copy['num_edificio']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea II\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminacion de duplicados en licencias.csv\n",
    "licencias_copy.drop_duplicates(subset=['id_local','ref_licencia'],inplace=True)\n",
    "licencias_copy.to_csv('Licencias_SinDuplicados.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pasar texto primera letra este en mayuscula y eliminar espacios en blanco\n",
    "cols_string = ['title','isbn','thumbnailUrl','shortDescription','longDescription','status','authors','categories']\n",
    "\n",
    "for col in cols_string:\n",
    "    books_copy[col] = books_copy[col].astype(str).str.capitalize().str.strip().str.replace(r'\\s+', ' ', regex=True)\n",
    "\n",
    "# guardar archivo editado\n",
    "books_copy.to_json('Books_Limpio.json', orient='records', lines=True)\n",
    "\n",
    "# realizamos lo mismo con los otros archivos\n",
    "datasets = [licencias_copy, terrazas_copy, locales_copy]\n",
    "\n",
    "for dataset in datasets:\n",
    "    cols_string = dataset.select_dtypes(include=['object']).columns\n",
    "    for col in cols_string:\n",
    "        dataset[col] = dataset[col].astype(str).str.capitalize().str.strip().str.replace(r'\\s+', ' ', regex=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea III"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inner join de Terrazas_Normalizadas y Licencias_SinDuplicados con id_local\n",
    "\n",
    "terrazas_normalizadas = pd.read_csv('Terrazas_Normalizadas.csv')\n",
    "licencias_sinduplicados = pd.read_csv('Licencias_SinDuplicados.csv')\n",
    "df_inner = pd.merge(terrazas_normalizadas, licencias_sinduplicados, on='id_local', how='inner')\n",
    "df_inner['coordenada_x_local_x'] = df_inner['coordenada_x_local_x'].str.replace(',', '.')\n",
    "df_inner['coordenada_y_local_x'] = df_inner['coordenada_y_local_x'].str.replace(',', '.')\n",
    "df_inner['coordenada_x_local_y'] = df_inner['coordenada_x_local_y'].str.replace(',', '.')\n",
    "df_inner['coordenada_y_local_y'] = df_inner['coordenada_y_local_y'].str.replace(',', '.')\n",
    "\n",
    "df_inner.to_csv('Licencias_Terrazas_Integradas.csv', index=False,encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregacion por barrio y usma de de superficies de terrazas del dataset terrazas.csv\n",
    "terrazas_agg = terrazas_copy.groupby(['desc_barrio_local']).agg({'Superficie_TO':'sum', 'Superficie_ES':'sum','Superficie_RA':'sum'}).sort_values(by='Superficie_TO', ascending=False).round(2)\n",
    "terrazas_agg.to_csv('Terrazas_Agregadas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "locales_agg = locales_copy.groupby(\n",
    "    ['desc_distrito_local']).agg({'Residuo':'sum'}\n",
    "                                 ).sort_values(by='Residuo', ascending=False\n",
    "                                               ).round(2)\n",
    "locales_agg.to_csv('Locales_Agregados.csv')\n",
    "licencias_agg = licencias_copy.groupby(\n",
    "    ['desc_barrio_local', 'desc_tipo_situacion_licencia']\n",
    ").size().reset_index(name='count').sort_values(by='count', ascending=False)\n",
    "licencias_agg.to_csv('Licencias_Agregadas.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenar datasets\n",
    "# primero creamos una copia de licencias_locales y guardamos como Licencias_Locales_202105\n",
    "licencias_copy.to_csv('Licencias_Locales_202105.csv', index=False)\n",
    "licencias_copy_2 = pd.read_csv('Licencias_Locales_202105.csv')\n",
    "# concatenamos los datasets\n",
    "licencias_concat = pd.concat([licencias_copy, licencias_copy_2], axis=0)\n",
    "licencias_concat_sin_duplicados = licencias_concat.drop_duplicates(subset=['id_local'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "terrazas_cols=['id_local','clase_vial_edificio','desc_vial_edificio','id_terraza','Superficie_TO','Ratio']\n",
    "locales_cols=['id_local','desc_distrito_local','desc_barrio_local','desc_tipo_acceso_local','clase_vial_acceso','desc_vial_acceso','num_edificio','Residuo']\n",
    "df_concat = pd.concat([terrazas_copy[terrazas_cols], locales_copy[locales_cols]], axis=1)\n",
    "df_concat_sin_duplicados = df_concat.drop_duplicates(subset=['id_local'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
