{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importacion de bibliotecas\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llamamos los archivos csv y json\n",
    "licencias_pd = pd.read_csv('Licencias_Locales_202104.csv', delimiter=';')\n",
    "terrazas_pd = pd.read_csv('Terrazas_202104.csv', delimiter=';', encoding='ISO-8859-1')\n",
    "locales_pd = pd.read_csv('Locales_202104.csv', delimiter=';', encoding='ISO-8859-1')\n",
    "books_pd = pd.read_json('books_edit_corrected.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension archivo licencias.csv:  (132171, 46)\n",
      "dimension archivo terrazas.csv:  (6275, 57)\n",
      "dimension archivo locales.csv:  (148216, 40)\n",
      "dimension archivo books.json:  (431, 11)\n",
      "\n",
      "dimension archivo licencias.csv editado:  (132171, 43)\n",
      "dimension archivo terrazas.csv editado:  (6275, 53)\n",
      "dimension archivo locales.csv editado:  (148216, 28)\n",
      "dimension archivo books.json editado:  (431, 11)\n"
     ]
    }
   ],
   "source": [
    "# eliminar columnas con mas del 50% de datos nulos\n",
    "licencias_copy = licencias_pd.copy()\n",
    "terrazas_copy = terrazas_pd.copy()\n",
    "locales_copy = locales_pd.copy()\n",
    "books_copy = books_pd.copy()\n",
    "print(\"dimension archivo licencias.csv: \",licencias_copy.shape)\n",
    "print(\"dimension archivo terrazas.csv: \",terrazas_copy.shape)\n",
    "print(\"dimension archivo locales.csv: \",locales_copy.shape)\n",
    "print(\"dimension archivo books.json: \",books_copy.shape)\n",
    "datasets = [licencias_copy, terrazas_copy, locales_copy, books_copy]\n",
    "\n",
    "for dataset in datasets:\n",
    "    threshold = len(dataset) * 0.5\n",
    "    dataset.dropna(thresh=threshold, axis=1, inplace=True)\n",
    "\n",
    "print(\"\\ndimension archivo licencias.csv editado: \",licencias_copy.shape)\n",
    "print(\"dimension archivo terrazas.csv editado: \",terrazas_copy.shape)\n",
    "print(\"dimension archivo locales.csv editado: \",locales_copy.shape)\n",
    "print(\"dimension archivo books.json editado: \",books_copy.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 132171 entries, 0 to 132170\n",
      "Data columns (total 43 columns):\n",
      " #   Column                        Non-Null Count   Dtype \n",
      "---  ------                        --------------   ----- \n",
      " 0   id_local                      132171 non-null  int64 \n",
      " 1   id_distrito_local             132171 non-null  int64 \n",
      " 2   desc_distrito_local           132171 non-null  object\n",
      " 3   id_barrio_local               132171 non-null  int64 \n",
      " 4   desc_barrio_local             132171 non-null  object\n",
      " 5   cod_barrio_local              132171 non-null  int64 \n",
      " 6   id_seccion_censal_local       132171 non-null  int64 \n",
      " 7   desc_seccion_censal_local     132171 non-null  int64 \n",
      " 8   coordenada_x_local            132171 non-null  object\n",
      " 9   coordenada_y_local            132171 non-null  object\n",
      " 10  id_tipo_acceso_local          132171 non-null  int64 \n",
      " 11  desc_tipo_acceso_local        132171 non-null  object\n",
      " 12  id_situacion_local            132171 non-null  int64 \n",
      " 13  desc_situacion_local          132171 non-null  object\n",
      " 14  id_ndp_edificio               132171 non-null  int64 \n",
      " 15  id_clase_ndp_edificio         132171 non-null  int64 \n",
      " 16  id_vial_edificio              132171 non-null  int64 \n",
      " 17  clase_vial_edificio           132171 non-null  object\n",
      " 18  desc_vial_edificio            132171 non-null  object\n",
      " 19  nom_edificio                  132171 non-null  object\n",
      " 20  num_edificio                  132171 non-null  int64 \n",
      " 21  cal_edificio                  132171 non-null  object\n",
      " 22  secuencial_local_PC           132171 non-null  int64 \n",
      " 23  id_ndp_acceso                 132171 non-null  int64 \n",
      " 24  id_clase_ndp_acceso           132171 non-null  int64 \n",
      " 25  id_vial_acceso                132171 non-null  int64 \n",
      " 26  clase_vial_acceso             132171 non-null  object\n",
      " 27  desc_vial_acceso              132171 non-null  object\n",
      " 28  nom_acceso                    132171 non-null  object\n",
      " 29  num_acceso                    132171 non-null  int64 \n",
      " 30  cal_acceso                    132171 non-null  object\n",
      " 31  id_agrupacion                 132171 non-null  int64 \n",
      " 32  nombre_agrupacion             132171 non-null  object\n",
      " 33  id_tipo_agrup                 132171 non-null  int64 \n",
      " 34  desc_tipo_agrup               132171 non-null  object\n",
      " 35  id_planta_agrupado            131859 non-null  object\n",
      " 36  rotulo                        132171 non-null  object\n",
      " 37  ref_licencia                  132171 non-null  object\n",
      " 38  id_tipo_licencia              132171 non-null  int64 \n",
      " 39  desc_tipo_licencia            132171 non-null  object\n",
      " 40  id_tipo_situacion_licencia    132171 non-null  int64 \n",
      " 41  desc_tipo_situacion_licencia  132171 non-null  object\n",
      " 42  Fecha_Dec_Lic                 132171 non-null  object\n",
      "dtypes: int64(21), object(22)\n",
      "memory usage: 43.4+ MB\n"
     ]
    }
   ],
   "source": [
    "licencias_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estandarizar columnas numericas con StandardScaler\n",
    "datasets = [licencias_copy, terrazas_copy, locales_copy, books_copy]\n",
    "\n",
    "#cambiar decimal de ',' a '.'\n",
    "terrazas_copy['Superficie_ES'] = terrazas_copy['Superficie_ES'].str.replace(',', '.')\n",
    "terrazas_copy['Superficie_RA'] = terrazas_copy['Superficie_RA'].str.replace(',', '.')\n",
    "\n",
    "# primero creamos en dataset Terrazas una columna Superficie_TO que es la suma de Superficie_ES y Superficie_RA\n",
    "terrazas_copy['Superficie_ES'] = terrazas_copy['Superficie_ES'].astype(float)\n",
    "terrazas_copy['Superficie_RA'] = terrazas_copy['Superficie_RA'].astype(float)\n",
    "terrazas_copy['Superficie_TO'] = terrazas_copy['Superficie_ES'] + terrazas_copy['Superficie_RA']\n",
    "\n",
    "for dataset in datasets:\n",
    "    numeric_cols = dataset.select_dtypes(include=['float64', 'int64']).columns\n",
    "    scaler = StandardScaler()\n",
    "    dataset[numeric_cols] = scaler.fit_transform(dataset[numeric_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creacion columna Ratio de Superficie_TO/id_terraza en terrazas.csv\n",
    "terrazas_copy['Ratio'] = terrazas_copy['Superficie_TO'] / terrazas_copy['id_terraza']\n",
    "# guardamos el archivo editado\n",
    "terrazas_copy.to_csv('Terrazas_Normalizadas.csv', index=False)\n",
    "\n",
    "# Producto de num_acceso * id_tipo_licencia en licencias.csv\n",
    "licencias_copy['Producto'] = licencias_copy['num_acceso'] * licencias_copy['id_tipo_licencia']\n",
    "\n",
    "# Residuo desc_seccion_censal_local /num_edificio en locales.csv\n",
    "locales_copy['Residuo'] = locales_copy['desc_seccion_censal_local'] % locales_copy['num_edificio']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea II\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminacion de duplicados en licencias.csv\n",
    "licencias_copy.drop_duplicates(subset=['id_local','ref_licencia'],inplace=True)\n",
    "licencias_copy.to_csv('Licencias_SinDuplicados.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pasar texto primera letra este en mayuscula y eliminar espacios en blanco\n",
    "cols_string = ['title','isbn','thumbnailUrl','shortDescription','longDescription','status','authors','categories']\n",
    "\n",
    "for col in cols_string:\n",
    "    books_copy[col] = books_copy[col].astype(str).str.capitalize().str.strip().str.replace(r'\\s+', ' ', regex=True)\n",
    "\n",
    "# guardar archivo editado\n",
    "books_copy.to_json('Books_Limpio.json', orient='records', lines=True)\n",
    "\n",
    "# realizamos lo mismo con los otros archivos\n",
    "datasets = [licencias_copy, terrazas_copy, locales_copy]\n",
    "\n",
    "for dataset in datasets:\n",
    "    cols_string = dataset.select_dtypes(include=['object']).columns\n",
    "    for col in cols_string:\n",
    "        dataset[col] = dataset[col].astype(str).str.capitalize().str.strip().str.replace(r'\\s+', ' ', regex=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea III"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inner join de Terrazas_Normalizadas y Licencias_SinDuplicados con id_local\n",
    "\n",
    "terrazas_normalizadas = pd.read_csv('Terrazas_Normalizadas.csv')\n",
    "licencias_sinduplicados = pd.read_csv('Licencias_SinDuplicados.csv')\n",
    "\n",
    "df_inner = pd.merge(terrazas_normalizadas, licencias_sinduplicados, on='id_local', how='inner')\n",
    "df_inner.to_csv('Licencias_Terrazas_Integradas.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregacion por barrio y usma de de superficies de terrazas del dataset terrazas.csv\n",
    "terrazas_agg = terrazas_copy.groupby(['desc_barrio_local']).agg({'Superficie_TO':'sum', 'Superficie_ES':'sum','Superficie_RA':'sum'}).sort_values(by='Superficie_TO', ascending=False).round(2)\n",
    "terrazas_agg.to_csv('Terrazas_Agregadas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "locales_agg = locales_copy.groupby(\n",
    "    ['desc_distrito_local']).agg({'Residuo':'sum'}\n",
    "                                 ).sort_values(by='Residuo', ascending=False\n",
    "                                               ).round(2)\n",
    "locales_agg.to_csv('Locales_Agregados.csv')\n",
    "licencias_agg = licencias_copy.groupby(\n",
    "    ['desc_barrio_local', 'desc_tipo_situacion_licencia']\n",
    ").size().reset_index(name='count').sort_values(by='count', ascending=False)\n",
    "licencias_agg.to_csv('Licencias_Agregadas.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenar datasets\n",
    "# primero creamos una copia de licencias_locales y guardamos como Licencias_Locales_202105\n",
    "licencias_copy.to_csv('Licencias_Locales_202105.csv', index=False)\n",
    "licencias_copy_2 = pd.read_csv('Licencias_Locales_202105.csv')\n",
    "# concatenamos los datasets\n",
    "licencias_concat = pd.concat([licencias_copy, licencias_copy_2], axis=0)\n",
    "licencias_concat_sin_duplicados = licencias_concat.drop_duplicates(subset=['id_local'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "terrazas_cols=['id_local','clase_vial_edificio','desc_vial_edificio','id_terraza','Superficie_TO','Ratio']\n",
    "locales_cols=['id_local','desc_distrito_local','desc_barrio_local','desc_tipo_acceso_local','clase_vial_acceso','desc_vial_acceso','num_edificio','Residuo']\n",
    "df_concat = pd.concat([terrazas_copy[terrazas_cols], locales_copy[locales_cols]], axis=1)\n",
    "df_concat_sin_duplicados = df_concat.drop_duplicates(subset=['id_local'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
